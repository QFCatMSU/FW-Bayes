---
title: Fitting nonlinear ecological models in Stan   
title-slide-attributes:
    data-background-image: "https://qfcatmsu.github.io/Images/dark-big.png"  
    data-background-size: "40%"
    data-background-position: "6% 95%"
subtitle: FW 891
author: Christopher Cahill
date: 18 September 2023
date-format: "D MMMM YYYY"
format: 
  revealjs:
    css: "https://qfcatmsu.github.io/css/presStyle.css"
    slide-number: c/t  
    theme: simple 
editor: visual
highlight-style: kate
---

## Purpose

- Introduce nonlinear models
- Demonstrate how those models can be powerful for answering bespoke resource management questions
- Demonstrate some tricks for fitting nonlinear models 
- Gain familiarity with non-standard models and estimating them in Stan

## Nonlinear modeling is like wandering down a sketchy alley with no end in sight

![](images/sketch.png){fig-align="center" width="700" height="500"}

## However...

- Bespoke ecological relationships critical for answering management relevant questions 
  - Building models for a specific problem at hand rather than shoe-horning a dataset into an easy modeling framework 
  - Often yields important insights into ecology and hence for resource mgmt
  - Many agency-collected datasets have been scoured by analysts using simpler linear modeling tools (GLM, GLMM), so nonlinear modeling is often a powerful way to look at old datsets through fresh eyes 

[see Cahill et al. 2018; Cahill et al. 2022]{.footerRight}


## What is a nonlinear model

- A nonlinear model is a model in which the predicted values are nonlinear functions of the parameters, not necessarily of the predictor variables

- This is a linear model because y is a linear function of a, b, and c even though it is a nonlinear function of x:

$$y = a + bx + cx^2$$

- Whereas the following power-law is a nonlinear model:
$$
y = ax^b
$$

[Bolker et al. 2013]{.footerRight}

## Linearizing the model via algebra

- We could linearize the previous equation by taking logarithms
$$
log(y) = log(a) + b \cdot log(x)
$$

- We could solve the nonlinear equation on the previous slide using something like `nls()` or via the linear model above using `lm()` in R 
- However:
  - Nonlinear version assumes a constant standard deviation and the linear version assumes a constant coefficient of variation 

## Where do nonlinear model equations come from? 

  ![](images/stork.png){fig-align="center" width="700" height="500"}

## Where do nonlinear model equations come from? 

- Often (but not always) formulated based on biological first principles 
  - Typically represented as something like a differential equation (examples: Predator-prey models, Stock-Recruitment models, Somatic Growth models, logistic population growth, meta-population models, etc.)
  - This means that estimating the parameters of these models is more likely to yield ecologically relevant insights

[see examples in Ricker 1954; Beverton and Holt 1957; Brännström and Sumpter 2005]{.footerRight}

## Deriving a nonlinear model: an example 

- The von Bertalanffy growth model is often usedto report fish growth patterns
  - Derived from a bioenergetics model: 
$$
 \frac{\mathrm{d} W}{\mathrm{~d} t}=H W_{t}^{\frac{2}{3}}-m W_{t}
$$

where W is weight at time t, H and m are mass-specific anabolic (tissue building) and catabolic (breaking down tissue) terms

[Beverton and Holt 1957]{.footerRight}

## Deriving a nonlinear model: an example 

Solving that differential equation, and transforming from weight to length yields the von Bertalanffy growth model:
$$
\hat{l}_{i}=l_{\infty}\left\{1-\mathrm{e}^{\left[-(K)\left(a_{i}-t_{0}\right)\right]}\right\}
$$

- where $a_{i}$ and $\hat{l}_{i}$ are the age and predicted length of fish i
- $l_{\infty}$ is a parameter that represents the average asymptotic maximum length of fish
- K is the unitless Brody “growth” coefficient
- t0 is a nuisance parameter that describes age when
length is hypothetically zero

## Visualizing that model in R

```{R echo = F, eval = T}
library(tidyverse)
library(ggqfc)
```


```{R echo = T, eval = T}
ages <- 0:25 # vector of ages
K <- 0.2
t0 <- 0.0
Linf <- 575
lengths <- Linf*(1-exp(-K*(ages-t0))) 
df <- data.frame(length = lengths, age = ages)

df %>%
  ggplot(aes(x = age, y = length)) + 
  ylim(0, 600) + geom_line(color = "steelblue", lwd = 2.5) + theme_qfc()

```

## Visualizing the model

![](images/vonB1.png){style="width:185px; position: absolute; bottom:7.5%; right:10%;"}

[Figure credit: Jim Bence]{.footerRight}

## Visualizing the model

![](images/vonB2.png){style="width:185px; position: absolute; bottom:7.5%; right:10%;"}

[Figure credit: Jim Bence]{.footerRight}


## Why this nonlinear hogwash is neat

- The model on the previous slide implies the following

$$
l_{\infty}=\frac{H}{m} \cdot \alpha^{-\frac{1}{3}}
$$

where $\alpha$ is the shape parameter from a weight-length relationship, and 

$$
K=\frac{m}{3}
$$

so it allows us to explicitly model the ecological processes we are interested in if we are clever!

## *Some* challenges associated with nonlinear modeling 

::: {style="font-size:30px"}

- Requires a better handle on both math/calculus and numerical computing
- Need to understand the properties of a variety of probability distributions and deterministic response functions (Link and Barber 2010; Bolker et al. 2013)
  - Even after a model has been properly formulated, it can be difficult to fit to data and estimate parameters
  - No gaurantees of global optimum, which means model checking and priors even more important
- There is no "dummies" guide to nonlinear ecological model fitting
- Critical to have good starting values, priors, tests with simulated data, etc.
:::

![](images/despair.png){style="width:185px; position: absolute; bottom:7.5%; left:42%;"}

![](images/depression.png){style="width:185px; position: absolute; bottom:5.5%; left:0%;"}


[see Bolker et al. 2013]{.footerRight}

## Advice (from Bolker et al. 2013)

- Most complex models are extensions of simpler models
  - Thus, often makes sense to fit reduced versions of the model and build up working code blocks 
  - Can use reduced models to get good starting values for more complex models in some cases
- Choose a subset of your data that makes your code run fast during the debugging stage
- Keep It Simple Stupid (KISS), at least to start

![](images/kiss.png){style="width:185px; position: absolute; bottom:5.5%; right:0%;"}

## Advice cont'd (Gelman and Hill 2006)

<br>
*"Our general approach to finding problems in statistical modeling software is to get various crude models or models with no predictors to work and then gradually build up to the model we want to fit.  If you set up a complicated model and you cannot get it to run (or it does and its results do not make sense) then either build it up from scratch or strip it down until you can get it to work and make sense"*

## Unidentifiability (Bolker 2009)

- In extreme cases, may try to fit *unidentifiable* models  
  - These are models that cannot, either in principle or more often in practice, be fitted at all with the available data
- Happens to inexperienced/enthusiastic modelers, but also experts
- Use common sense (thinking about your model) and do model checks 
- Simulated data can help us better understand a model, too 

## Specific suggestions to overcome problems

::: {style="font-size:30px"}

- Initially omit complexities of the model as much as possible (random effects, zero inflation, imprefect detection)
- Hold some parameters constant or set strong priors to restrict parameters to a narrow range
- Reduce the model to a simpler form by setting some parameters, especially exponents or shape parameters, to null values
  - e.g., try a Poisson model before a negative binomial model
  - or an exponential suvival model before a Gamma model
:::

[Bolker et al. 2013]{.footerLeft}

![](images/detective.png){style="width:185px; position: absolute; bottom:5.5%; right:0%;"}

## Pick reasonable starting values

- Starting the optimization or simulation routine sufficiently close to the best values often makes the difference between success and failure
- Stan doesn't require you to pick starting values (it will do so for you), but...
- Most important step: make sure initial parameter values are on the right order of magnitude
  - For parameters that are very uncertain, estimating the logarithms of the original parameters can be helpful
  - Plot the data and eyeball initial values, overlay predictions for initial values on the data 

[Bolker et al. 2013]{.footerRight}

## Reshape the goodness of fit surface 

- Think of the problem geometrically, as an attempt to map out the posterior surface
  - Posterior geometry is a function of priors, model structure, and the information content within your data
- One can often improve the shape of the posterior, and hence the stability and efficiency of Stan (or other software platforms) without changing the biological meaning of the model or its goodness of fit 
  - Reparameterization may be unnecessary, helpful, or essential to solving a specific problem 

[Bolker et al. 2013]{.footerRight}

## Simulation

- Mentioned this before, but simulation is perhaps the single most valuable tool for debugging complex models
- Code up the data generating process(DGP), and give your estimation model good data to see if it can recover truth
  - Can reduce data quality to mirror challenges observed or perceived in the real data once you get your model running
  - Helps you find bugs, identify unidentifiability, better understand your model, etc.
  - Critical component of a modern Bayesian workflow, and the best case scenario is that the estimator is able to recover true parameters

[Hilborn and Mangel 1997; Gelman et al. 2022]{.footerRight}

## Scaling

- Parameters with strongly different scales lead to likelihood surfaces with different slopes or curvatures in different directions
  - Often causes numerical problems 
- Rescaling parameters by appropriate constants can imrpove robustness of fit
- Researchers often scale predictor variables by standard deviation
- See this link:
  - [https://mc-stan.org/docs/stan-users-guide/standardizing-predictors-and-outputs.html](https://mc-stan.org/docs/stan-users-guide/standardizing-predictors-and-outputs.html)

[Bolker et al. 2013]{.footerRight}

## Remove correlation in the likelihood surface

- Strongly correlated likelihood surfaces can be difficult for MCMC algorithms
- One simple strategy:
  - Centering predictor variables, by subracting their mean or something near the center of the distribution of the predictor variable
  - Centering redefines the intercept or reference level of the model and strongly reduces correlation between slope and intercept parameters
  - Also improves interpretability 
[Bolker et al. 2013]{.footerRight}

## In class examples

  1. von Bertalanffy model to estimate fish growth (fake data where I know truth but you do not; *easy*)
  
  2. Type-II predator-prey model for wolves and moose (real data from Isle Royale; *intermediate*)

  3. Schaefer surplus-production model to estimate maximum sustainable yield (real data from south Atlantic Albacore Tuna; *hard*)

  ![](images/wolf.png){style="height:150px; position: absolute; bottom:8.5%; left:5%;"}

  ![](images/tuna.png){style="height:150px; position: absolute; bottom:8.5%; left:35%;"}

   ![](images/moose.png){style="height:150px; position: absolute; bottom:8.5%; right:5%;"}

## The von Bertalanffy growth model 

![](images/fish.png){style="width:185px; position: absolute; bottom:5.5%; right:10%;"}

## The von Bertalanffy growth model 

- [The data](https://github.com/QFCatMSU/FW-Bayes/blob/main/week4/data/age_length.rds?raw=true)

- The model:
$$
\begin{array}{l}
L_{i}=L_{\infty}\left(1-e^{-K\left(a_{i}-t_{0}\right)}\right)+\varepsilon_{i} \\
\varepsilon_{i} \stackrel{i i d}{\sim} N\left(0, \sigma^{2}\right)
\end{array}
$$

- Groups of three or fewer, fit this model using Stan 

## References

::: {style="font-size:20px"}

Beverton and Holt. 1957. On the dynamics of exploited fish populations. Chapman and Hall. 

Bolker, B. 2009. Learning hierarchical models: advice for the rest of us. Ecological Applications, 19, 588–592.

Bolker et al. 2013.  Strategies for fitting nonlinear ecological models in R, AD Model Builder, and BUGS.  Methods in Ecology and Evolution. doi: 10.1111/2041-210X.12044

Brännström and Sumpter. 2005. The role of competition and clustering in population dynamics. Proceedings of the Royal Society B. doi: https://doi.org/10.1098/rspb.2005.3185

Cahill et al. 2018.  Multiple challenges confront a high effort inland recreational fishery in decline. Canadian Journal of Fisheries and Aquatic Sciences. 

Cahill et al. 2022.  Unveiling the recovery dynamics of walleye after the invisible collapse.  Canadian Journal of Fisheries and Aquatic Sciences. 

Gelman and Hill 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. 

Gelman et al. 2020.  Regression and other stories.  Cambridge University Press.

Hilborn and Mangel 1997.  The Ecological Detective.

Link and Barber 2010.


Beverton-Holt
Ricker 1954
Lotka-Volterra 
:::
